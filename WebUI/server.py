import importlib.util
import json
import logging
import math
import os
import sqlite3
import subprocess
import sys
import time
from typing import List, Dict, Any

logger = logging.getLogger("tianyan_plugin")

# è‡ªåŠ¨å®‰è£…ä¾èµ–
# noinspection PyUnusedImports
def install_dependencies():
    """è‡ªåŠ¨å®‰è£…å¿…è¦çš„Pythonä¾èµ–"""

    # è¦æ£€æŸ¥çš„å¿…éœ€åŒ…åˆ—è¡¨
    required_packages = ['fastapi', 'uvicorn', 'pydantic']

    # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
    missing_packages = []
    for package in required_packages:
        spec = importlib.util.find_spec(package)
        if spec is None:
            missing_packages.append(package)

    if not missing_packages:
        # print("All required dependencies are installed.")
        return True

    print(f"Missing dependencies found: {missing_packages}")
    print("Attempting automatic installation...")

    # æ£€æŸ¥pipæ˜¯å¦å¯ç”¨
    try:
        # å°è¯•å¯¼å…¥pip
        import pip
        print("pip installed, version:", pip.__version__)
    except ImportError:
        print("pip not found, trying to install pip...")
        try:
            # ä½¿ç”¨ensurepipå®‰è£…pip
            import ensurepip
            subprocess.check_call([sys.executable, "-m", "ensurepip", "--upgrade"])
            print("pip installed successfully")
        except Exception as error:
            print(f"Failed to install pip: {error}")
            print("Please install pip manually: https://pip.pypa.io/en/stable/installation/")
            return False

    # å®‰è£…ç¼ºå¤±çš„åŒ…
    try:
        # é¦–å…ˆå‡çº§pip
        subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "pip"])

        requirements_file = os.path.join(os.path.dirname(__file__), "requirements.txt")
        if os.path.exists(requirements_file):
            print(f"Using requirements.txt to install dependencies: {requirements_file}")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", requirements_file])
        else:
            # å¦åˆ™åªå®‰è£…ç¼ºå¤±çš„åŒ…
            print("requirements.txt not found, installing missing packages...")
            for package in missing_packages:
                print(f"Installing {package}...")
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])

        print("Dependencies installed successfully!")
        return True

    except subprocess.CalledProcessError as error:
        print(f"Failed to install dependencies: {error}")
        return False
    except Exception as error:
        print(f"Unknown error during installation: {error}")
        return False


def verify_dependencies():
    """éªŒè¯æ‰€æœ‰å¿…éœ€ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    required_packages = ['fastapi', 'uvicorn', 'pydantic']

    # print("Verifying dependencies...")
    missing_packages = []

    for package in required_packages:
        try:
            importlib.import_module(package)
        except ImportError as error:
            missing_packages.append(package)
            print(f"âœ— {package} not installed: {error}")

    if missing_packages:
        print(f"\nMissing required dependencies: {missing_packages}")
        print("Attempting automatic installation...")

        if install_dependencies():
            # é‡æ–°éªŒè¯
            print("\nRe-verifying dependencies...")
            final_missing = []
            for package in required_packages:
                try:
                    importlib.import_module(package)
                except ImportError:
                    final_missing.append(package)

            if final_missing:
                print(f"\nError: Failed to install the following dependencies: {final_missing}")
                print("Please install manually: pip install " + " ".join(final_missing))
                return False
            else:
                print("\nAll dependencies installed successfully!")
                return True
        else:
            print("\nAutomatic installation failed, please install dependencies manually.")
            print("Please run: pip install " + " ".join(missing_packages))
            return False
    else:
        return True


# åœ¨å¯¼å…¥ç¬¬ä¸‰æ–¹åº“ä¹‹å‰éªŒè¯ä¾èµ–
if __name__ != "__main__":
    # å¦‚æœæ˜¯è¢«å¯¼å…¥çš„ï¼Œè·³è¿‡ä¾èµ–æ£€æŸ¥
    pass
else:
    # ä¸»ç¨‹åºè¿è¡Œæ—¶éªŒè¯ä¾èµ–
    if not verify_dependencies():
        print("Dependency check failed, program exiting.")
        sys.exit(1)

try:
    # noinspection PyUnusedImports
    import uvicorn
    # noinspection PyUnusedImports
    from fastapi import FastAPI, Header, HTTPException, Query
    # noinspection PyUnusedImports
    from fastapi.middleware.cors import CORSMiddleware
    # noinspection PyUnusedImports
    from pydantic import BaseModel
    # noinspection PyUnusedImports
    from fastapi.staticfiles import StaticFiles
    # noinspection PyUnusedImports
    from fastapi.responses import FileResponse
except ImportError as e:
    print(f"Failed to import third-party libraries: {e}")
    print("Please ensure all dependencies are installed:")
    print("pip install fastapi uvicorn pydantic")
    sys.exit(1)

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨çš„ç»å¯¹è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# print(f"Base directory: {BASE_DIR}")
# å¼ºåˆ¶åˆ‡æ¢å·¥ä½œç›®å½•åˆ° WebUI æ–‡ä»¶å¤¹
os.chdir(BASE_DIR)

# é‡æ–°å®šä½è·¯å¾„ï¼ˆç›¸å¯¹äº WebUI æ–‡ä»¶å¤¹ï¼‰
DB_PATH = "../ty_data.db"
CONFIG_PATH = "../web_config.json"
LOG_PATH = "../logs/webui.log"
LANGUAGES_DIR = "languages"

# ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)

# å…¨å±€è°ƒè¯•æ ‡å¿—
DEBUG_MODE = "--debug" in sys.argv


def load_config() -> dict:
    """å®‰å…¨åŠ è½½é…ç½®æ–‡ä»¶ï¼Œå¸¦é»˜è®¤å€¼å’Œé”™è¯¯å¤„ç†"""
    default_config = {
        "secret": "",
        "backend_port": 8098,
        # å¯æ ¹æ®éœ€è¦æ·»åŠ å…¶ä»–é»˜è®¤é¡¹
    }
    if not os.path.exists(CONFIG_PATH):
        logging.warning(f"Config file not found. Generating template at {CONFIG_PATH}")
        template = {
            "secret": "your_secret",
            "backend_port": 8098
        }
        with open(CONFIG_PATH, 'w', encoding='utf-8') as cf:
            json.dump(template, cf, indent=4, ensure_ascii=False)
        return template

    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as cf:
            the_config = json.load(cf)
            # åˆå¹¶é»˜è®¤å€¼ï¼ˆåªè¡¥å……ç¼ºå¤±å­—æ®µï¼‰
            for key, value in default_config.items():
                if key not in the_config:
                    the_config[key] = value
            return the_config
    except json.JSONDecodeError as error:
        logging.error(f"Invalid JSON in config file {CONFIG_PATH}: {error}")
        raise RuntimeError(f"Configuration file is not valid JSON: {error}")
    except Exception as error:
        logging.error(f"Failed to load config file {CONFIG_PATH}: {error}")
        raise RuntimeError(f"Cannot load configuration: {error}")


def load_language(lang_code="en_US"):
    """åŠ è½½è¯­è¨€æ–‡ä»¶"""
    lang_file = os.path.join(BASE_DIR, LANGUAGES_DIR, f"{lang_code}.json")

    # å¦‚æœè¯·æ±‚çš„è¯­è¨€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå›é€€åˆ°è‹±æ–‡
    if not os.path.exists(lang_file):
        lang_file = os.path.join(BASE_DIR, LANGUAGES_DIR, "en_US.json")

    try:
        with open(lang_file, 'r', encoding='utf-8') as lf:
            return json.load(lf)
    except Exception as error:
        logging.error(f"Failed to load language file {lang_file}: {error}")
        # è¿”å›ç©ºå­—å…¸
        return {}


# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging():
    """é…ç½®æ—¥å¿—ï¼Œè¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°"""
    global logger
    # æ ¹æ®è°ƒè¯•æ¨¡å¼è®¾ç½®æ—¥å¿—çº§åˆ«
    if DEBUG_MODE:
        logger.setLevel(logging.DEBUG)
    else:
        logger.setLevel(logging.INFO)

    # ç§»é™¤æ‰€æœ‰ç°æœ‰çš„å¤„ç†å™¨
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)

    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(LOG_PATH), exist_ok=True)

    # ğŸ‘‡ æ¯æ¬¡å¯åŠ¨æ—¶æ¸…ç©ºæ—¥å¿—æ–‡ä»¶å†…å®¹
    with open(LOG_PATH, 'w', encoding='utf-8'):
        pass

    # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(LOG_PATH, encoding='utf-8')
    if DEBUG_MODE:
        file_handler.setLevel(logging.DEBUG)
    else:
        file_handler.setLevel(logging.INFO)

    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼æˆ–æ€»æ˜¯è¾“å‡ºï¼‰
    console_handler = logging.StreamHandler()
    if DEBUG_MODE:
        console_handler.setLevel(logging.DEBUG)
    else:
        console_handler.setLevel(logging.INFO)

    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    # æ·»åŠ åˆ° logger
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    # è®¾ç½®uvicornæ—¥å¿—
    if DEBUG_MODE:
        # è°ƒè¯•æ¨¡å¼ä¸‹ä¿ç•™æ›´å¤šæ—¥å¿—
        logging.getLogger("uvicorn").setLevel(logging.DEBUG)
        logging.getLogger("uvicorn.access").setLevel(logging.DEBUG)
        logging.getLogger("uvicorn.error").setLevel(logging.DEBUG)
    else:
        # ç”Ÿäº§æ¨¡å¼ä¸‹å‡å°‘æ—¥å¿—
        logging.getLogger("uvicorn").handlers = []
        logging.getLogger("uvicorn.access").handlers = []
        logging.getLogger("uvicorn.error").handlers = []


# è®¾ç½®æ—¥å¿—
setup_logging()

app = FastAPI()
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])


# è·å–å¯ç”¨è¯­è¨€åˆ—è¡¨
@app.get("/api/languages")
async def get_languages():
    """è·å–å¯ç”¨çš„è¯­è¨€åˆ—è¡¨"""
    languages = []
    if os.path.exists(LANGUAGES_DIR):
        for file in os.listdir(LANGUAGES_DIR):
            if file.endswith(".json"):
                lang_code = file.replace(".json", "")
                languages.append(lang_code)

    # ç¡®ä¿è‡³å°‘è¿”å›è‹±æ–‡
    if "en_US" not in languages:
        languages.append("en_US")

    return {"languages": sorted(languages), "default": "en_US"}


# è·å–è¯­è¨€æ–‡ä»¶å†…å®¹
@app.get("/api/language/{lang_code}")
async def get_language(lang_code: str):
    """è·å–æŒ‡å®šè¯­è¨€æ–‡ä»¶å†…å®¹"""
    return load_language(lang_code)


# è¾…åŠ©å‡½æ•°ï¼šè·å–æ–‡ä»¶å¤§å°
def get_db_size():
    if os.path.exists(DB_PATH):
        size_bytes = os.path.getsize(DB_PATH)
        return f"{size_bytes / (1024 * 1024):.2f} MB"
    return "0 MB"


# æ•°æ®æ¨¡å‹
class LogsResponse(BaseModel):
    data: List[Dict]
    total: int
    page: int
    page_size: int
    total_pages: int
    query_time_ms: float


@app.get("/api/stats")
async def get_stats(x_secret: str = Header(None)):
    web_config = load_config()
    if x_secret != web_config.get("secret"):
        raise HTTPException(status_code=403, detail="Secret Invalid")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM LOGDATA")
    total_count = cursor.fetchone()[0]
    conn.close()

    return {
        "total_logs": total_count,
        "db_size": get_db_size(),
        "server_time": int(time.time())
    }


@app.get("/api/logs", response_model=LogsResponse)
async def get_logs(
        page: int = Query(1, ge=1, description="é¡µç "),
        page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ¡æ•°"),
        start_time: int = Query(None, description="å¼€å§‹æ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰"),
        end_time: int = Query(None, description="ç»“æŸæ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰"),
        filter_type: str = Query(None, description="è¿‡æ»¤å­—æ®µç±»å‹"),
        filter_value: str = Query(None, description="è¿‡æ»¤å€¼ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰"),
        center_x: float = Query(None, description="ä¸­å¿ƒç‚¹Xåæ ‡"),
        center_y: float = Query(None, description="ä¸­å¿ƒç‚¹Yåæ ‡"),
        center_z: float = Query(None, description="ä¸­å¿ƒç‚¹Zåæ ‡"),
        radius: float = Query(None, description="æŸ¥è¯¢åŠå¾„ï¼ˆæ ¼ï¼‰"),
        dimension: str = Query(None, description="ç»´åº¦åç§°"),
        x_secret: str = Header(None),
        x_lang: str = Header("en_US")
):
    start_time_query = time.time()  # è®°å½•æŸ¥è¯¢å¼€å§‹æ—¶é—´

    web_config = load_config()
    if x_secret != web_config.get("secret"):
        raise HTTPException(status_code=403, detail="Secret Invalid")

    # æ£€æŸ¥åæ ‡æŸ¥è¯¢å‚æ•°
    has_coord_query = all([center_x is not None, center_y is not None, center_z is not None, radius is not None])
    if any([center_x is not None, center_y is not None, center_z is not None, radius is not None]):
        if not has_coord_query:
            raise HTTPException(
                status_code=400,
                detail="åæ ‡æŸ¥è¯¢éœ€è¦å®Œæ•´å‚æ•°: center_x, center_y, center_z, radius"
            )
        if radius < 0:
            raise HTTPException(status_code=400, detail="åŠå¾„ä¸èƒ½ä¸ºè´Ÿæ•°")

    # è®°å½•è¯·æ±‚å‚æ•°ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
    if DEBUG_MODE:
        logging.debug(f"API /logs è¯·æ±‚å‚æ•°:")
        logging.debug(f"  page={page}, page_size={page_size}")
        logging.debug(f"  start_time={start_time}, end_time={end_time}")
        logging.debug(f"  filter_type={filter_type}, filter_value={filter_value}")
        logging.debug(f"  center_x={center_x}, center_y={center_y}, center_z={center_z}, radius={radius}")
        logging.debug(f"  dimension={dimension}")
        logging.debug(f"  has_coord_query={has_coord_query}")

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row

    try:
        cursor = conn.cursor()
        # æ„å»ºè®¡æ•°æŸ¥è¯¢ - ç”¨äºè·å–æ€»è®°å½•æ•°
        count_query = "SELECT COUNT(*) FROM LOGDATA WHERE 1=1"
        data_query = "SELECT * FROM LOGDATA WHERE 1=1"
        count_params = []
        data_params = []

        # æ—¶é—´èŒƒå›´è¿‡æ»¤
        if start_time:
            count_query += " AND time >= ?"
            data_query += " AND time >= ?"
            count_params.append(start_time)
            data_params.append(start_time)
        if end_time:
            count_query += " AND time <= ?"
            data_query += " AND time <= ?"
            count_params.append(end_time)
            data_params.append(end_time)

        # å­—æ®µè¿‡æ»¤ï¼ˆä½¿ç”¨LIKEè¿›è¡Œæ¨¡ç³ŠåŒ¹é…ï¼‰
        if filter_type and filter_value:
            # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢ SQL æ³¨å…¥
            allowed_fields = ["id", "name", "type", "obj_id", "obj_name", "world", "status", "data"]
            if filter_type in allowed_fields:
                # å…³é”®ä¿®å¤ï¼šå…ˆç¡®ä¿å­—æ®µä¸ä¸ºNULLä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå†è¿›è¡ŒLIKEåŒ¹é…
                # è¿™æ ·å¯ä»¥é¿å…NULLå€¼å¯¼è‡´çš„æ„å¤–åŒ¹é…
                count_query += f" AND ({filter_type} IS NOT NULL AND {filter_type} != '' AND {filter_type} LIKE ?)"
                data_query += f" AND ({filter_type} IS NOT NULL AND {filter_type} != '' AND {filter_type} LIKE ?)"
                count_params.append(f"%{filter_value}%")
                data_params.append(f"%{filter_value}%")

        # ç»´åº¦è¿‡æ»¤ - å…³é”®ä¿®å¤ï¼šæ­£ç¡®å¤„ç†ç»´åº¦å‚æ•°
        if dimension:
            if dimension.lower() == "all" or dimension == "" or dimension is None:
                # å…¨éƒ¨ç»´åº¦ï¼Œä¸åšè¿‡æ»¤
                pass
            else:
                count_query += " AND world = ?"
                data_query += " AND world = ?"
                count_params.append(dimension)
                data_params.append(dimension)

        # åæ ‡èŒƒå›´è¿‡æ»¤ï¼ˆç‹¬ç«‹äºå…¶ä»–è¿‡æ»¤å™¨ï¼‰
        if has_coord_query:
            # å…ˆç¡®ä¿åæ ‡å€¼æœ‰æ•ˆï¼Œé¿å…NULLå€¼å¯¼è‡´çš„è®¡ç®—é—®é¢˜
            valid_coord_condition = " AND pos_x IS NOT NULL AND pos_y IS NOT NULL AND pos_z IS NOT NULL"
            count_query += valid_coord_condition
            data_query += valid_coord_condition

            # ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»å…¬å¼ (x-x0)Â² + (y-y0)Â² + (z-z0)Â² <= radiusÂ²
            distance_condition = f"""
                AND ((pos_x - ?) * (pos_x - ?) + 
                    (pos_y - ?) * (pos_y - ?) + 
                    (pos_z - ?) * (pos_z - ?)) <= (? * ?)
            """
            count_query += distance_condition
            data_query += distance_condition
            # æ·»åŠ å‚æ•°
            params = [center_x, center_x, center_y, center_y, center_z, center_z, radius, radius]
            count_params.extend(params)
            data_params.extend(params)

        # è®°å½•SQLè¯­å¥ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        if DEBUG_MODE:
            logging.debug(f"è®¡æ•°æŸ¥è¯¢SQL: {count_query}")
            logging.debug(f"è®¡æ•°æŸ¥è¯¢å‚æ•°: {count_params}")
            logging.debug(f"æ•°æ®æŸ¥è¯¢SQL: {data_query}")
            logging.debug(f"æ•°æ®æŸ¥è¯¢å‚æ•°: {data_params}")

        # æ‰§è¡Œè®¡æ•°æŸ¥è¯¢
        cursor.execute(count_query, count_params)
        total_records = cursor.fetchone()[0]

        # è®¡ç®—åˆ†é¡µ
        offset = (page - 1) * page_size
        total_pages = (total_records + page_size - 1) // page_size  # å‘ä¸Šå–æ•´

        # æ„å»ºæ•°æ®æŸ¥è¯¢ï¼ˆå¸¦æ’åºå’Œåˆ†é¡µï¼‰
        data_query += " ORDER BY time DESC LIMIT ? OFFSET ?"
        data_params.extend([page_size, offset])

        # è®°å½•å®Œæ•´çš„SQLè¯­å¥ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        if DEBUG_MODE:
            logging.debug(f"æœ€ç»ˆæ•°æ®æŸ¥è¯¢SQL: {data_query}")
            logging.debug(f"æœ€ç»ˆæ•°æ®æŸ¥è¯¢å‚æ•°: {data_params}")

        # æ‰§è¡Œæ•°æ®æŸ¥è¯¢
        cursor.execute(data_query, data_params)
        rows = cursor.fetchall()

        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = []
        for row in rows:
            record: Dict[str, Any] = dict(row)
            # ä¸ºæ¯æ¡è®°å½•è®¡ç®—è·ç¦»ï¼ˆå¦‚æœè¿›è¡Œäº†åæ ‡æŸ¥è¯¢ï¼‰
            if has_coord_query:
                dx = float(record["pos_x"]) - center_x
                dy = float(record["pos_y"]) - center_y
                dz = float(record["pos_z"]) - center_z
                distance = math.sqrt(dx * dx + dy * dy + dz * dz)
                record["distance"] = round(distance, 2)
            data.append(record)

        query_time = (time.time() - start_time_query) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

        # è®°å½•æŸ¥è¯¢ç»“æœï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        if DEBUG_MODE:
            logging.debug(f"æŸ¥è¯¢ç»“æœ: æ‰¾åˆ° {len(data)} æ¡è®°å½•ï¼Œæ€»è®¡ {total_records} æ¡")
            logging.debug(f"æŸ¥è¯¢è€—æ—¶: {query_time:.2f} æ¯«ç§’")
            if len(data) > 0:
                # åªè®°å½•å‰å‡ æ¡è®°å½•çš„ä¿¡æ¯
                for i, record in enumerate(data[:3]):
                    logging.debug(
                        f"è®°å½• {i + 1}: id={record.get('id')}, name={record.get('name')}, type={record.get('type')}, obj_id={record.get('obj_id')}")

        return LogsResponse(
            data=data,
            total=total_records,
            page=page,
            page_size=page_size,
            total_pages=total_pages,
            query_time_ms=round(query_time, 2)
        )

    except sqlite3.Error as error:
        current_data_query = locals().get('data_query', 'æœªçŸ¥æŸ¥è¯¢')
        current_data_params = locals().get('data_params', [])
        logging.error(f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(error)}")
        logging.error(f"å‡ºé”™çš„SQLè¯­å¥: {current_data_query}")
        logging.error(f"SQLå‚æ•°: {current_data_params}")
        raise HTTPException(status_code=500, detail=f"æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(error)}")
    finally:
        conn.close()


# æ–°å¢ï¼šæ‰¹é‡æŸ¥è¯¢æ¥å£ï¼ˆç”¨äºå¯¼å‡ºï¼‰
@app.get("/api/export")
async def export_logs(
        start_page: int = Query(1, ge=1, description="å¼€å§‹é¡µç "),
        end_page: int = Query(1, ge=1, description="ç»“æŸé¡µç "),
        page_size: int = Query(100, ge=1, le=500, description="æ¯é¡µæ¡æ•°"),
        start_time: int = Query(None, description="å¼€å§‹æ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰"),
        end_time: int = Query(None, description="ç»“æŸæ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰"),
        filter_type: str = Query(None, description="è¿‡æ»¤å­—æ®µç±»å‹"),
        filter_value: str = Query(None, description="è¿‡æ»¤å€¼ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰"),
        center_x: float = Query(None, description="ä¸­å¿ƒç‚¹Xåæ ‡"),
        center_y: float = Query(None, description="ä¸­å¿ƒç‚¹Yåæ ‡"),
        center_z: float = Query(None, description="ä¸­å¿ƒç‚¹Zåæ ‡"),
        radius: float = Query(None, description="æŸ¥è¯¢åŠå¾„ï¼ˆæ ¼ï¼‰"),
        dimension: str = Query(None, description="ç»´åº¦åç§°"),
        x_secret: str = Header(None),
        x_lang: str = Header("en_US")
):
    web_config = load_config()
    if x_secret != web_config.get("secret"):
        raise HTTPException(status_code=403, detail="Secret Invalid")

    if start_page > end_page:
        raise HTTPException(status_code=400, detail="å¼€å§‹é¡µç ä¸èƒ½å¤§äºç»“æŸé¡µç ")

    if (end_page - start_page + 1) * page_size > 50000:
        raise HTTPException(status_code=400, detail="å¯¼å‡ºæ•°æ®é‡è¿‡å¤§ï¼Œæœ€å¤š50000æ¡")

    # è®°å½•è¯·æ±‚å‚æ•°ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
    if DEBUG_MODE:
        logging.debug(f"API /export è¯·æ±‚å‚æ•°:")
        logging.debug(f"  start_page={start_page}, end_page={end_page}, page_size={page_size}")
        logging.debug(f"  start_time={start_time}, end_time={end_time}")
        logging.debug(f"  filter_type={filter_type}, filter_value={filter_value}")
        logging.debug(f"  center_x={center_x}, center_y={center_y}, center_z={center_z}, radius={radius}")
        logging.debug(f"  dimension={dimension}")

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row

    try:
        cursor = conn.cursor()

        # å…ˆè·å–æ»¡è¶³æ¡ä»¶çš„æ•°æ®æ€»æ•°
        count_query = "SELECT COUNT(*) FROM LOGDATA WHERE 1=1"
        count_params = []

        # æ—¶é—´èŒƒå›´è¿‡æ»¤
        if start_time:
            count_query += " AND time >= ?"
            count_params.append(start_time)
        if end_time:
            count_query += " AND time <= ?"
            count_params.append(end_time)

        # å­—æ®µè¿‡æ»¤ï¼ˆå…³é”®ä¿®å¤ï¼šéœ€è¦ä¸get_logså‡½æ•°ä¿æŒä¸€è‡´ï¼‰
        if filter_type and filter_value:
            allowed_fields = ["id", "name", "type", "obj_id", "obj_name", "world", "status", "data"]
            if filter_type in allowed_fields:
                # å…³é”®ä¿®å¤ï¼šå…ˆç¡®ä¿å­—æ®µä¸ä¸ºNULLä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå†è¿›è¡ŒLIKEåŒ¹é…
                count_query += f" AND ({filter_type} IS NOT NULL AND {filter_type} != '' AND {filter_type} LIKE ?)"
                count_params.append(f"%{filter_value}%")

        # ç»´åº¦è¿‡æ»¤ - å…³é”®ä¿®å¤
        if dimension and dimension.lower() != "all" and dimension != "" and dimension is not None:
            count_query += " AND world = ?"
            count_params.append(dimension)

        # åæ ‡èŒƒå›´è¿‡æ»¤
        has_coord_query = all([center_x is not None, center_y is not None, center_z is not None, radius is not None])
        if has_coord_query:
            # å…ˆç¡®ä¿åæ ‡å€¼æœ‰æ•ˆï¼Œé¿å…NULLå€¼å¯¼è‡´çš„è®¡ç®—é—®é¢˜
            valid_coord_condition = " AND pos_x IS NOT NULL AND pos_y IS NOT NULL AND pos_z IS NOT NULL"
            count_query += valid_coord_condition

            distance_condition = f"""
                AND ((pos_x - ?) * (pos_x - ?) + 
                    (pos_y - ?) * (pos_y - ?) + 
                    (pos_z - ?) * (pos_z - ?)) <= (? * ?)
            """
            count_query += distance_condition
            params = [center_x, center_x, center_y, center_y, center_z, center_z, radius, radius]
            count_params.extend(params)

        # è®°å½•è®¡æ•°æŸ¥è¯¢SQLï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        if DEBUG_MODE:
            logging.debug(f"å¯¼å‡ºè®¡æ•°æŸ¥è¯¢SQL: {count_query}")
            logging.debug(f"å¯¼å‡ºè®¡æ•°æŸ¥è¯¢å‚æ•°: {count_params}")

        cursor.execute(count_query, count_params)
        total_records = cursor.fetchone()[0]

        # è®¡ç®—å®é™…çš„ç»“æŸé¡µç 
        total_pages = (total_records + page_size - 1) // page_size
        actual_end_page = min(end_page, total_pages)

        if start_page > total_pages:
            logging.warning(f"å¯¼å‡ºè¯·æ±‚å¼€å§‹é¡µç  {start_page} è¶…å‡ºæ€»é¡µæ•° {total_pages}")
            return {
                "data": [],
                "total_records": 0,
                "exported_records": 0,
                "pages_exported": 0,
                "message": f"å¼€å§‹é¡µç  {start_page} è¶…å‡ºæ€»é¡µæ•° {total_pages}"
            }

        # å¾ªç¯è·å–æ‰€æœ‰é¡µçš„æ•°æ®
        all_data = []
        for page_num in range(start_page, actual_end_page + 1):
            offset = (page_num - 1) * page_size

            data_query = "SELECT * FROM LOGDATA WHERE 1=1"
            data_params = []

            # æ—¶é—´èŒƒå›´è¿‡æ»¤
            if start_time:
                data_query += " AND time >= ?"
                data_params.append(start_time)
            if end_time:
                data_query += " AND time <= ?"
                data_params.append(end_time)

            # å­—æ®µè¿‡æ»¤ï¼ˆå…³é”®ä¿®å¤ï¼šéœ€è¦ä¸è®¡æ•°æŸ¥è¯¢ä¿æŒä¸€è‡´ï¼‰
            if filter_type and filter_value:
                allowed_fields = ["id", "name", "type", "obj_id", "obj_name", "world", "status", "data"]
                if filter_type in allowed_fields:
                    # å…³é”®ä¿®å¤ï¼šå…ˆç¡®ä¿å­—æ®µä¸ä¸ºNULLä¸”ä¸ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œå†è¿›è¡ŒLIKEåŒ¹é…
                    data_query += f" AND ({filter_type} IS NOT NULL AND {filter_type} != '' AND {filter_type} LIKE ?)"
                    data_params.append(f"%{filter_value}%")

            # ç»´åº¦è¿‡æ»¤ - å…³é”®ä¿®å¤
            if dimension and dimension.lower() != "all" and dimension != "" and dimension is not None:
                data_query += " AND world = ?"
                data_params.append(dimension)

            # åæ ‡èŒƒå›´è¿‡æ»¤
            if has_coord_query:
                distance_condition = f"""
                    AND ((pos_x - ?) * (pos_x - ?) + 
                         (pos_y - ?) * (pos_y - ?) + 
                         (pos_z - ?) * (pos_z - ?)) <= (? * ?)
                """
                data_query += distance_condition
                params = [center_x, center_x, center_y, center_y, center_z, center_z, radius, radius]
                data_params.extend(params)

            data_query += " ORDER BY time DESC LIMIT ? OFFSET ?"
            data_params.extend([page_size, offset])

            # è®°å½•æ¯é¡µçš„SQLï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
            if DEBUG_MODE:
                logging.debug(f"å¯¼å‡ºç¬¬ {page_num} é¡µSQL: {data_query}")
                logging.debug(f"å¯¼å‡ºç¬¬ {page_num} é¡µå‚æ•°: {data_params}")

            cursor.execute(data_query, data_params)
            rows = cursor.fetchall()
            for row in rows:
                record: Dict[str, Any] = dict(row)
                # ä¸ºæ¯æ¡è®°å½•è®¡ç®—è·ç¦»ï¼ˆå¦‚æœè¿›è¡Œäº†åæ ‡æŸ¥è¯¢ï¼‰
                if has_coord_query:
                    dx = float(record["pos_x"]) - center_x
                    dy = float(record["pos_y"]) - center_y
                    dz = float(record["pos_z"]) - center_z
                    distance = math.sqrt(dx * dx + dy * dy + dz * dz)
                    record["distance"] = round(distance, 2)
                all_data.append(record)

        # è®°å½•å¯¼å‡ºç»“æœï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
        if DEBUG_MODE:
            logging.debug(f"å¯¼å‡ºç»“æœ: å…±å¯¼å‡º {len(all_data)} æ¡è®°å½•")
            logging.debug(f"å¯¼å‡ºé¡µæ•°: ä» {start_page} é¡µåˆ° {actual_end_page} é¡µ")
            if len(all_data) > 0:
                # åªè®°å½•å‰å‡ æ¡è®°å½•çš„ä¿¡æ¯
                for i, record in enumerate(all_data[:3]):
                    logging.debug(
                        f"å¯¼å‡ºè®°å½• {i + 1}: id={record.get('id')}, name={record.get('name')}, type={record.get('type')}, obj_id={record.get('obj_id')}")

        return {
            "data": all_data,
            "total_records": total_records,
            "exported_records": len(all_data),
            "pages_exported": actual_end_page - start_page + 1,
            "start_page": start_page,
            "end_page": actual_end_page,
            "total_pages": total_pages
        }

    except sqlite3.Error as error:
        current_data_query = locals().get('data_query', 'æœªçŸ¥æŸ¥è¯¢')
        current_data_params = locals().get('data_params', [])
        logging.error(f"å¯¼å‡ºæ•°æ®é”™è¯¯: {str(error)}")
        logging.error(f"å‡ºé”™çš„SQLè¯­å¥: {current_data_query}")
        logging.error(f"SQLå‚æ•°: {current_data_params}")
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºæ•°æ®é”™è¯¯: {str(error)}")
    finally:
        conn.close()


# æ–°å¢ï¼šè·å–æ•°æ®åº“ç´¢å¼•çŠ¶æ€å’Œå»ºè®®
@app.get("/api/db_info")
async def get_db_info(x_secret: str = Header(None)):
    web_config = load_config()
    if x_secret != web_config.get("secret"):
        raise HTTPException(status_code=403, detail="Secret Invalid")

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    try:
        # è·å–è¡¨ä¿¡æ¯
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]

        # è·å–ç´¢å¼•ä¿¡æ¯
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index' AND tbl_name='LOGDATA'")
        indexes = [row[0] for row in cursor.fetchall()]

        # è·å–åˆ—ä¿¡æ¯
        cursor.execute("PRAGMA table_info(LOGDATA)")
        columns = [{"name": row[1], "type": row[2], "notnull": row[3], "pk": row[5]} for row in cursor.fetchall()]

        # åˆ†ææŸ¥è¯¢æ€§èƒ½
        cursor.execute("SELECT COUNT(*) FROM LOGDATA")
        total_rows = cursor.fetchone()[0]

        return {
            "tables": tables,
            "indexes": indexes,
            "columns": columns,
            "total_rows": total_rows
        }
    finally:
        conn.close()


# ç”¨äºè°ƒè¯•
@app.get("/api/debug/query")
async def debug_query(
        sql: str = Query(None, description="SQLæŸ¥è¯¢è¯­å¥"),
        x_secret: str = Header(None)
):
    """è°ƒè¯•æ¥å£ï¼šç›´æ¥æ‰§è¡ŒSQLæŸ¥è¯¢ï¼ˆä»…è°ƒè¯•æ¨¡å¼å¯ç”¨ï¼‰"""
    if not DEBUG_MODE:
        raise HTTPException(status_code=403, detail="æ­¤æ¥å£ä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹å¯ç”¨")

    web_config = load_config()
    if x_secret != web_config.get("secret"):
        raise HTTPException(status_code=403, detail="Secret Invalid")

    if not sql or not sql.strip():
        raise HTTPException(status_code=400, detail="éœ€è¦æä¾›SQLæŸ¥è¯¢è¯­å¥")

    # å®‰å…¨æ£€æŸ¥ï¼šé™åˆ¶ä¸ºSELECTæŸ¥è¯¢
    if not sql.strip().upper().startswith("SELECT"):
        raise HTTPException(status_code=400, detail="åªå…è®¸SELECTæŸ¥è¯¢")

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row

    try:
        cursor = conn.cursor()
        logging.info(f"è°ƒè¯•æŸ¥è¯¢æ‰§è¡ŒSQL: {sql}")

        cursor.execute(sql)
        rows = cursor.fetchall()

        # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
        data = []
        for row in rows:
            data.append(dict(row))

        return {
            "success": True,
            "row_count": len(data),
            "data": data[:100],  # é™åˆ¶è¿”å›å‰100æ¡
            "total": len(data)
        }
    except sqlite3.Error as error:
        logging.error(f"è°ƒè¯•æŸ¥è¯¢é”™è¯¯: {str(error)}")
        return {
            "success": False,
            "error": str(error)
        }
    finally:
        conn.close()


@app.get("/")
async def get_index():
    return FileResponse(os.path.join(BASE_DIR, "index.html"))


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦ä»¥è°ƒè¯•æ¨¡å¼å¯åŠ¨
    if DEBUG_MODE:
        print(f"Boot mode: DEBUG")
        print(f"Database Path: {DB_PATH}")
        print(f"Config file: {CONFIG_PATH}")
        print(f"Log file: {LOG_PATH}")
        print(f"Languages Path: {LANGUAGES_DIR}")

    conf = load_config()
    # é…ç½®uvicornè¿è¡Œå‚æ•°
    config = {
        "host": "0.0.0.0",
        "port": conf.get("backend_port", 8098),
        "log_config": None,  # ç¦ç”¨uvicornçš„é»˜è®¤æ—¥å¿—é…ç½®
        "access_log": DEBUG_MODE,  # ä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹å¯ç”¨è®¿é—®æ—¥å¿—
        "log_level": "debug" if DEBUG_MODE else "warning"  # è®¾ç½®æ—¥å¿—çº§åˆ«
    }

    logger.info(f"Start WebUI Serviceï¼Œ127.0.0.1:{config['port']}")
    if conf.get("secret", "your_secret") == "your_secret":
        logger.warning("Using the default secret 'your_secret' â€” please update it for better security.")

    uvicorn.run(app, **config)